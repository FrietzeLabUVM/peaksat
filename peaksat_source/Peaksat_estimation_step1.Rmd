---
title: "Peaksat Read Depth Estimation"
author: "Cong Gao"
date: "11/04/2022"
output: html_document
---

## *Peaksat* pipeline step 1; job submission
This is an R markdown file to show how to run peaksat pipeline, here we use H4K5ac as an example

```{r setup, include=FALSE}
# rm(list=ls())
library(peaksat)
library(magrittr)
```

### Step1: Locate Bam Files 
```{r load bam files, echo=FALSE}
#locate files
bam_files = dir("/slipstream/home/conggao/ChIP_seq/MCF10_H4Kac/", full.names = TRUE, pattern = "(H4K5ac|input).+rep.+bam$")
bam_files = bam_files[file.exists(bam_files)]
bam_files = bam_files[c(1:2, 5:14)]
bam_files
```

### Step 2: Put target files with correspondent input files together 
```{r}
dt = data.table(file = bam_files)
dt[, c("cell", "mark", "rep") := tstrsplit(basename(file), "[_\\.]", keep = 1:3)]
dt$cell %>% table

dt_inputs = dt[mark == "input"][, .(input_file = file, cell)]
file.exists(paste0(dt_inputs$input_file, ".bai"))
dt_inputs[, input_reads := ssvQC::get_mapped_reads(input_file), .(input_file)]

mark_grouped = split(dt, dt$mark)
mark_grouped = mark_grouped[setdiff(names(mark_grouped), "input")]

todo = lapply(mark_grouped, function(mark_dt){
  merge(mark_dt, dt_inputs, by = "cell")
})
```

### Step 3: Run pipeline on computing cluster, then save peakset 
```{r}
pc = peaksat_config(out_dir = "/slipstream/home/conggao/peak_saturation/MCF10_H4Kac_Nov2022/")
pc
td = todo[[1]]
lapply(todo, function(td){
  submit_peaksat_jobs(psc = pc, treat_bams = td$file, ctrl_bams = td$input_file, await_completion = FALSE)
})

```




